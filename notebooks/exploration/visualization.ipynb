{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2383d52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(908446, 9)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "RAW_DIR = Path(\"../raw\")   \n",
    "PROCESSED_DIR = Path(\"../processed\")\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TICKER = \"AAPL\"\n",
    "START_DATE = \"2016-01-01\"\n",
    "END_DATE   = \"2025-12-31\"\n",
    "\n",
    "vs_path = RAW_DIR / f\"{TICKER}_vsurfd_{START_DATE}_{END_DATE}.csv.gz\"\n",
    "\n",
    "\n",
    "vs = pd.read_csv(vs_path, parse_dates=[\"date\"])\n",
    "\n",
    "\n",
    "vs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3cd03f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date range: 2016-01-04 00:00:00 -> 2025-08-29 00:00:00\n",
      "unique dates: 2429\n",
      "unique days: 11\n",
      "unique deltas: 34\n",
      "cp: ['P', 'C']\n",
      "Categories (2, object): ['C', 'P']\n"
     ]
    }
   ],
   "source": [
    "# Ensure types\n",
    "vs[\"days\"] = vs[\"days\"].astype(int)\n",
    "vs[\"cp_flag\"] = vs[\"cp_flag\"].str.upper().astype(\"category\")\n",
    "\n",
    "# Normalize delta: if it looks like 10..90 convert to 0.10..0.90\n",
    "if vs[\"delta\"].max() > 2:\n",
    "    vs[\"delta\"] = vs[\"delta\"] / 100.0\n",
    "\n",
    "print(\"date range:\", vs[\"date\"].min(), \"->\", vs[\"date\"].max())\n",
    "print(\"unique dates:\", vs[\"date\"].nunique())\n",
    "print(\"unique days:\", vs[\"days\"].nunique())\n",
    "print(\"unique deltas:\", vs[\"delta\"].nunique())\n",
    "print(\"cp:\", vs[\"cp_flag\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50b3527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "days_grid  = np.sort(vs[\"days\"].unique())\n",
    "delta_grid = np.sort(vs[\"delta\"].unique())\n",
    "dates = np.sort(vs[\"date\"].unique())\n",
    "\n",
    "def build_surface_matrix(day_vs, cp=\"C\"):\n",
    "    # pivot to days x delta\n",
    "    mat = (day_vs[day_vs[\"cp_flag\"] == cp]\n",
    "           .pivot_table(index=\"days\", columns=\"delta\", values=\"impl_volatility\", aggfunc=\"mean\")\n",
    "           .reindex(index=days_grid, columns=delta_grid))\n",
    "\n",
    "    # fill missing values lightly for visualization\n",
    "    mat = mat.copy()\n",
    "    mat = mat.interpolate(axis=1, limit_direction=\"both\")  # along delta\n",
    "    mat = mat.interpolate(axis=0, limit_direction=\"both\")  # along days\n",
    "    mat = mat.ffill().bfill()\n",
    "\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87ab3e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126c4f40d3244a778212369101d0b687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=0, description='Date', max=2428), ToggleButtons(description='Side', options=(('…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5504f20931e04a509b14f95d174a8afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "date_slider = widgets.IntSlider(min=0, max=len(dates)-1, step=1, value=0, description=\"Date\")\n",
    "cp_toggle = widgets.ToggleButtons(options=[(\"Call\", \"C\"), (\"Put\", \"P\")], description=\"Side\")\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "def render(date_idx, cp):\n",
    "    d = pd.to_datetime(dates[date_idx])\n",
    "    day_vs = vs[vs[\"date\"] == d]\n",
    "    mat = build_surface_matrix(day_vs, cp=cp)\n",
    "\n",
    "    # Build X/Y mesh for plotly\n",
    "    X, Y = np.meshgrid(mat.columns.astype(float), mat.index.astype(int))\n",
    "    Z = mat.values.astype(float)\n",
    "\n",
    "    fig = go.Figure(data=[go.Surface(x=X, y=Y, z=Z)])\n",
    "    fig.update_layout(\n",
    "        title=f\"{'CALL' if cp=='C' else 'PUT'} Vol Surface — {d.date()}\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"Delta\",\n",
    "            yaxis_title=\"Days to Expiration\",\n",
    "            zaxis_title=\"Implied Vol\",\n",
    "        ),\n",
    "        height=650,\n",
    "        width=950,\n",
    "        margin=dict(l=0, r=0, t=40, b=0),\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "def on_change(_=None):\n",
    "    out.clear_output(wait=True)\n",
    "    with out:\n",
    "        render(date_slider.value, cp_toggle.value)\n",
    "\n",
    "date_slider.observe(on_change, names=\"value\")\n",
    "cp_toggle.observe(on_change, names=\"value\")\n",
    "\n",
    "display(widgets.HBox([date_slider, cp_toggle]))\n",
    "display(out)\n",
    "\n",
    "on_change()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a879c06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secid</th>\n",
       "      <th>date</th>\n",
       "      <th>days</th>\n",
       "      <th>delta</th>\n",
       "      <th>cp_flag</th>\n",
       "      <th>impl_volatility</th>\n",
       "      <th>impl_strike</th>\n",
       "      <th>impl_premium</th>\n",
       "      <th>dispersion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101594.0</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>P</td>\n",
       "      <td>0.351577</td>\n",
       "      <td>113.5996</td>\n",
       "      <td>8.665669</td>\n",
       "      <td>0.214947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101594.0</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>P</td>\n",
       "      <td>0.296881</td>\n",
       "      <td>110.8722</td>\n",
       "      <td>6.048973</td>\n",
       "      <td>0.144321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101594.0</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>P</td>\n",
       "      <td>0.267112</td>\n",
       "      <td>109.3283</td>\n",
       "      <td>4.620924</td>\n",
       "      <td>0.069316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101594.0</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>P</td>\n",
       "      <td>0.261231</td>\n",
       "      <td>108.4435</td>\n",
       "      <td>3.891608</td>\n",
       "      <td>0.023896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101594.0</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>P</td>\n",
       "      <td>0.263302</td>\n",
       "      <td>107.7605</td>\n",
       "      <td>3.397845</td>\n",
       "      <td>0.007847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      secid       date  days  delta cp_flag  impl_volatility  impl_strike  \\\n",
       "0  101594.0 2016-01-04    10  -0.90       P         0.351577     113.5996   \n",
       "1  101594.0 2016-01-04    10  -0.85       P         0.296881     110.8722   \n",
       "2  101594.0 2016-01-04    10  -0.80       P         0.267112     109.3283   \n",
       "3  101594.0 2016-01-04    10  -0.75       P         0.261231     108.4435   \n",
       "4  101594.0 2016-01-04    10  -0.70       P         0.263302     107.7605   \n",
       "\n",
       "   impl_premium  dispersion  \n",
       "0      8.665669    0.214947  \n",
       "1      6.048973    0.144321  \n",
       "2      4.620924    0.069316  \n",
       "3      3.891608    0.023896  \n",
       "4      3.397845    0.007847  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "vs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61c9e950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\Admin\\OneDrive\\Desktop\\Fifth Year\\Computer Science\\CS4490 Thesis\\Codebase\\Thesis\\Data\\processed\\parquet\\AAPL_vsurf_processed.parquet\n",
      "Meta : C:\\Users\\Admin\\OneDrive\\Desktop\\Fifth Year\\Computer Science\\CS4490 Thesis\\Codebase\\Thesis\\Data\\processed\\meta\\AAPL_vsurf_processed_meta.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'secid_min': 101594,\n",
       " 'secid_max': 101594,\n",
       " 'date_min': '2016-01-04',\n",
       " 'date_max': '2025-08-29',\n",
       " 'n_rows': 908446,\n",
       " 'n_dates': 2429,\n",
       " 'n_days': 11,\n",
       " 'n_delta': 34,\n",
       " 'cp_flag_levels': ['C', 'P'],\n",
       " 'duplicate_rows_dropped': 0,\n",
       " 'columns': ['secid',\n",
       "  'date',\n",
       "  'days',\n",
       "  'delta',\n",
       "  'cp_flag',\n",
       "  'impl_volatility',\n",
       "  'impl_strike',\n",
       "  'impl_premium',\n",
       "  'dispersion'],\n",
       " 'notes': 'Minimal cleaning + deterministic dtypes; vendor signed delta preserved'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---- paths ----\n",
    "PROCESSED_DIR = Path(\"../processed\").resolve()\n",
    "PARQUET_DIR = PROCESSED_DIR / \"parquet\"\n",
    "META_DIR = PROCESSED_DIR / \"meta\"\n",
    "PARQUET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "META_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUT_PARQUET = PARQUET_DIR / \"AAPL_vsurf_processed.parquet\"\n",
    "OUT_META = META_DIR / \"AAPL_vsurf_processed_meta.json\"\n",
    "\n",
    "# ---- required columns ----\n",
    "required = [\n",
    "    \"secid\", \"date\", \"days\", \"delta\", \"cp_flag\",\n",
    "    \"impl_volatility\", \"impl_strike\", \"impl_premium\", \"dispersion\"\n",
    "]\n",
    "missing = [c for c in required if c not in vs.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "# ---- date parsing  ----\n",
    "vs[\"date\"] = pd.to_datetime(vs[\"date\"], errors=\"raise\").dt.normalize()\n",
    "\n",
    "# ---- types  ----\n",
    "vs[\"secid\"] = vs[\"secid\"].astype(\"int32\")\n",
    "vs[\"days\"] = pd.to_numeric(vs[\"days\"], errors=\"raise\").astype(\"float32\")\n",
    "vs[\"delta\"] = pd.to_numeric(vs[\"delta\"], errors=\"raise\").astype(\"float32\")\n",
    "vs[\"cp_flag\"] = vs[\"cp_flag\"].astype(\"category\")  # efficient in parquet\n",
    "\n",
    "for c in [\"impl_volatility\", \"impl_strike\", \"impl_premium\", \"dispersion\"]:\n",
    "    vs[c] = pd.to_numeric(vs[c], errors=\"raise\").astype(\"float32\")\n",
    "\n",
    "# ---- sanity filters  ----\n",
    "mask = (\n",
    "    (vs[\"days\"] > 0) &\n",
    "    np.isfinite(vs[\"impl_volatility\"]) & (vs[\"impl_volatility\"] > 0) &\n",
    "    np.isfinite(vs[\"impl_strike\"]) & (vs[\"impl_strike\"] > 0) &\n",
    "    np.isfinite(vs[\"impl_premium\"]) & (vs[\"impl_premium\"] >= 0) &\n",
    "    np.isfinite(vs[\"dispersion\"])\n",
    ")\n",
    "vs = vs.loc[mask].copy()\n",
    "\n",
    "# ---- uniqueness check per (date, maturity, delta, cp_flag) ----\n",
    "key = [\"date\", \"days\", \"delta\", \"cp_flag\"]\n",
    "dup_count = vs.duplicated(subset=key).sum()\n",
    "if dup_count > 0:\n",
    "    # If duplicates exist, keep the first :\n",
    "    vs = vs.drop_duplicates(subset=key, keep=\"first\").copy()\n",
    "\n",
    "# ---- sort for determinism/debugging ----\n",
    "vs = vs.sort_values([\"date\", \"days\", \"delta\", \"cp_flag\"]).reset_index(drop=True)\n",
    "\n",
    "# ---- write parquet ----\n",
    "vs.to_parquet(\n",
    "    OUT_PARQUET,\n",
    "    index=False,\n",
    "    engine=\"pyarrow\",\n",
    "    compression=\"zstd\"  \n",
    ")\n",
    "\n",
    "# ---- write small metadata file  ----\n",
    "meta = {\n",
    "    \"secid_min\": int(vs[\"secid\"].min()),\n",
    "    \"secid_max\": int(vs[\"secid\"].max()),\n",
    "    \"date_min\": str(vs[\"date\"].min().date()),\n",
    "    \"date_max\": str(vs[\"date\"].max().date()),\n",
    "    \"n_rows\": int(len(vs)),\n",
    "    \"n_dates\": int(vs[\"date\"].nunique()),\n",
    "    \"n_days\": int(vs[\"days\"].nunique()),\n",
    "    \"n_delta\": int(vs[\"delta\"].nunique()),\n",
    "    \"cp_flag_levels\": list(map(str, vs[\"cp_flag\"].cat.categories)),\n",
    "    \"duplicate_rows_dropped\": int(dup_count),\n",
    "    \"columns\": list(vs.columns),\n",
    "    \"notes\": \"Minimal cleaning + deterministic dtypes; vendor signed delta preserved\"\n",
    "}\n",
    "\n",
    "with open(OUT_META, \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Saved:\", OUT_PARQUET)\n",
    "print(\"Meta :\", OUT_META)\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "992a05c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: parquet\\AAPL_vsurf_processed.parquet\n",
      "Rows: 908446\n",
      "Date range: 2016-01-04 -> 2025-08-29\n",
      "Unique dates: 2429\n",
      "Unique maturities (days): 11 | min/max: 10.0 730.0\n",
      "Unique |delta|: 17 | min/max: 0.10000000149011612 0.8999999761581421\n",
      "cp_flag levels: ['C', 'P']\n",
      "\n",
      "Expected unique grid points per date: 374\n",
      "Coverage summary (actual/expected):\n",
      "count    2429.0\n",
      "mean        1.0\n",
      "std         0.0\n",
      "min         1.0\n",
      "1%          1.0\n",
      "5%          1.0\n",
      "10%         1.0\n",
      "50%         1.0\n",
      "90%         1.0\n",
      "95%         1.0\n",
      "99%         1.0\n",
      "max         1.0\n",
      "dtype: float64\n",
      "\n",
      "Dates with FULL global-grid coverage: 2429/2429 (100.00%)\n",
      "\n",
      "Unique maturities per date (days) summary:\n",
      "count    2429.0\n",
      "mean       11.0\n",
      "std         0.0\n",
      "min        11.0\n",
      "5%         11.0\n",
      "50%        11.0\n",
      "95%        11.0\n",
      "max        11.0\n",
      "Name: days, dtype: float64\n",
      "\n",
      "Unique |delta| per date summary:\n",
      "count    2429.0\n",
      "mean       17.0\n",
      "std         0.0\n",
      "min        17.0\n",
      "5%         17.0\n",
      "50%        17.0\n",
      "95%        17.0\n",
      "max        17.0\n",
      "Name: delta_abs, dtype: float64\n",
      "\n",
      "Intersection maturities (days) present on ALL dates: 11\n",
      "Intersection |delta| present on ALL dates: 17\n",
      "\n",
      "Top 15 maturities by date-coverage:\n",
      "days\n",
      "10.0     1.0\n",
      "30.0     1.0\n",
      "60.0     1.0\n",
      "91.0     1.0\n",
      "122.0    1.0\n",
      "152.0    1.0\n",
      "182.0    1.0\n",
      "273.0    1.0\n",
      "365.0    1.0\n",
      "547.0    1.0\n",
      "730.0    1.0\n",
      "Name: date, dtype: float64\n",
      "\n",
      "Top 15 |delta| by date-coverage:\n",
      "delta_abs\n",
      "0.10    1.0\n",
      "0.15    1.0\n",
      "0.20    1.0\n",
      "0.25    1.0\n",
      "0.30    1.0\n",
      "0.35    1.0\n",
      "0.40    1.0\n",
      "0.45    1.0\n",
      "0.50    1.0\n",
      "0.55    1.0\n",
      "0.60    1.0\n",
      "0.65    1.0\n",
      "0.70    1.0\n",
      "0.75    1.0\n",
      "0.80    1.0\n",
      "Name: date, dtype: float64\n",
      "\n",
      "All dates are complete on the global grid (days x |delta| x cp_flag).\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- locate parquet robustly (root vs Data/processed notebook cwd) ---\n",
    "candidates = [\n",
    "    Path(\"./Data/processed/parquet/AAPL_vsurf_processed.parquet\"),\n",
    "    Path(\"./processed/parquet/AAPL_vsurf_processed.parquet\"),\n",
    "    Path(\"../Data/processed/parquet/AAPL_vsurf_processed.parquet\"),\n",
    "    Path(\"./parquet/AAPL_vsurf_processed.parquet\"),\n",
    "]\n",
    "PARQUET_PATH = next((p for p in candidates if p.exists()), None)\n",
    "if PARQUET_PATH is None:\n",
    "    raise FileNotFoundError(\"Could not find AAPL_vsurf_processed.parquet in expected locations.\")\n",
    "\n",
    "vs = pd.read_parquet(PARQUET_PATH)\n",
    "\n",
    "# --- basic cardinalities ---\n",
    "vs[\"date\"] = pd.to_datetime(vs[\"date\"]).dt.normalize()\n",
    "vs[\"delta_abs\"] = vs[\"delta\"].abs().round(6)   # stable grouping key\n",
    "\n",
    "n_dates = vs[\"date\"].nunique()\n",
    "days_grid = np.sort(vs[\"days\"].unique())\n",
    "delta_abs_grid = np.sort(vs[\"delta_abs\"].unique())\n",
    "cp_levels = (\n",
    "    list(vs[\"cp_flag\"].cat.categories)\n",
    "    if str(vs[\"cp_flag\"].dtype) == \"category\"\n",
    "    else sorted(vs[\"cp_flag\"].unique())\n",
    ")\n",
    "\n",
    "print(\"Loaded:\", PARQUET_PATH)\n",
    "print(\"Rows:\", len(vs))\n",
    "print(\"Date range:\", vs[\"date\"].min().date(), \"->\", vs[\"date\"].max().date())\n",
    "print(\"Unique dates:\", n_dates)\n",
    "print(\"Unique maturities (days):\", len(days_grid), \"| min/max:\", float(days_grid.min()), float(days_grid.max()))\n",
    "print(\"Unique |delta|:\", len(delta_abs_grid), \"| min/max:\", float(delta_abs_grid.min()), float(delta_abs_grid.max()))\n",
    "print(\"cp_flag levels:\", cp_levels)\n",
    "\n",
    "# --- does each date have a \"complete\" surface on the global grid? (days x |delta| x cp_flag) ---\n",
    "# count unique grid points actually present per date\n",
    "combo_counts = (\n",
    "    vs.drop_duplicates([\"date\", \"days\", \"delta_abs\", \"cp_flag\"])\n",
    "      .groupby(\"date\")\n",
    "      .size()\n",
    ")\n",
    "\n",
    "expected_per_date = len(days_grid) * len(delta_abs_grid) * len(cp_levels)\n",
    "coverage = combo_counts / expected_per_date\n",
    "\n",
    "print(\"\\nExpected unique grid points per date:\", expected_per_date)\n",
    "print(\"Coverage summary (actual/expected):\")\n",
    "print(coverage.describe(percentiles=[0.01, 0.05, 0.1, 0.5, 0.9, 0.95, 0.99]))\n",
    "\n",
    "n_full = int((coverage == 1.0).sum())\n",
    "print(f\"\\nDates with FULL global-grid coverage: {n_full}/{n_dates} ({n_full/n_dates:.2%})\")\n",
    "\n",
    "# --- how stable are maturities/deltas across dates? ---\n",
    "days_per_date = vs.groupby(\"date\")[\"days\"].nunique()\n",
    "deltas_per_date = vs.groupby(\"date\")[\"delta_abs\"].nunique()\n",
    "\n",
    "print(\"\\nUnique maturities per date (days) summary:\")\n",
    "print(days_per_date.describe(percentiles=[0.05, 0.5, 0.95]))\n",
    "print(\"\\nUnique |delta| per date summary:\")\n",
    "print(deltas_per_date.describe(percentiles=[0.05, 0.5, 0.95]))\n",
    "\n",
    "# --- intersection grid (present on ALL dates) & top coverage grid points ---\n",
    "days_coverage = (vs.drop_duplicates([\"date\", \"days\"]).groupby(\"days\")[\"date\"].nunique() / n_dates).sort_values(ascending=False)\n",
    "delta_coverage = (vs.drop_duplicates([\"date\", \"delta_abs\"]).groupby(\"delta_abs\")[\"date\"].nunique() / n_dates).sort_values(ascending=False)\n",
    "\n",
    "common_days = days_coverage[days_coverage == 1.0].index.to_numpy()\n",
    "common_deltas = delta_coverage[delta_coverage == 1.0].index.to_numpy()\n",
    "\n",
    "print(\"\\nIntersection maturities (days) present on ALL dates:\", len(common_days))\n",
    "print(\"Intersection |delta| present on ALL dates:\", len(common_deltas))\n",
    "\n",
    "print(\"\\nTop 15 maturities by date-coverage:\")\n",
    "print(days_coverage.head(15))\n",
    "print(\"\\nTop 15 |delta| by date-coverage:\")\n",
    "print(delta_coverage.head(15))\n",
    "\n",
    "# --- show a concrete example of what's missing on the first incomplete date ---\n",
    "incomplete_dates = coverage[coverage < 1.0].index\n",
    "if len(incomplete_dates) > 0:\n",
    "    d0 = incomplete_dates[0]\n",
    "    df0 = vs[vs[\"date\"] == d0].drop_duplicates([\"days\", \"delta_abs\", \"cp_flag\"])\n",
    "    present = pd.MultiIndex.from_frame(df0[[\"days\", \"delta_abs\", \"cp_flag\"]])\n",
    "    all_idx = pd.MultiIndex.from_product([days_grid, delta_abs_grid, cp_levels], names=[\"days\", \"delta_abs\", \"cp_flag\"])\n",
    "    missing = all_idx.difference(present)\n",
    "\n",
    "    print(f\"\\nFirst incomplete date: {d0.date()} | missing points: {len(missing)}\")\n",
    "    print(\"First 25 missing (days, |delta|, cp_flag):\")\n",
    "    print(list(missing[:25]))\n",
    "else:\n",
    "    print(\"\\nAll dates are complete on the global grid (days x |delta| x cp_flag).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a97647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis (uv .venv)",
   "language": "python",
   "name": "thesis-uv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
