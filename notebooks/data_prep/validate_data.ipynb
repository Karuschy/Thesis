{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93bd53d1",
   "metadata": {},
   "source": [
    "# Validate Pulled Data for VAE vs Heston Comparison\n",
    "\n",
    "This notebook validates that all pulled WRDS data is consistent and ready for:\n",
    "1. **VAE Training** - Volatility surface data\n",
    "2. **Heston Calibration** - Zero curves + forward prices\n",
    "\n",
    "We need to ensure:\n",
    "- Same date coverage across all datasets\n",
    "- Compatible maturity grids (or identify interpolation needs)\n",
    "- No critical missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0512936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -------------------\n",
    "# CONFIG\n",
    "# -------------------\n",
    "TICKER = \"AAPL\"\n",
    "START_DATE = \"2016-01-01\"\n",
    "END_DATE = \"2025-12-31\"\n",
    "\n",
    "RAW_DIR = Path(\"../../data/raw/ivydb\")\n",
    "\n",
    "# File paths\n",
    "VS_PATH = RAW_DIR / \"vol_surface\" / f\"{TICKER}_vsurfd_{START_DATE}_{END_DATE}.csv.gz\"\n",
    "PX_PATH = RAW_DIR / \"security_price\" / f\"{TICKER}_underlying_{START_DATE}_{END_DATE}.csv.gz\"\n",
    "ZC_PATH = RAW_DIR / \"zero_curve\" / f\"zero_curve_{START_DATE}_{END_DATE}.csv.gz\"\n",
    "STDOP_PATH = RAW_DIR / \"std_option_price\" / f\"{TICKER}_stdopd_{START_DATE}_{END_DATE}.csv.gz\"\n",
    "\n",
    "print(\"Data files:\")\n",
    "for name, path in [(\"Vol Surface\", VS_PATH), (\"Underlying Px\", PX_PATH), \n",
    "                    (\"Zero Curve\", ZC_PATH), (\"Std Option\", STDOP_PATH)]:\n",
    "    exists = \"‚úì\" if path.exists() else \"‚úó MISSING\"\n",
    "    print(f\"  {exists} {name}: {path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97f02e4",
   "metadata": {},
   "source": [
    "## 1. Load All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6ad118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "vs = pd.read_csv(VS_PATH, parse_dates=[\"date\"])\n",
    "px = pd.read_csv(PX_PATH, parse_dates=[\"date\"])\n",
    "zc = pd.read_csv(ZC_PATH, parse_dates=[\"date\"])\n",
    "stdop = pd.read_csv(STDOP_PATH, parse_dates=[\"date\"])\n",
    "\n",
    "print(\"Dataset shapes:\")\n",
    "print(f\"  Volatility Surface: {vs.shape}\")\n",
    "print(f\"  Underlying Prices:  {px.shape}\")\n",
    "print(f\"  Zero Curve:         {zc.shape}\")\n",
    "print(f\"  Std Option Prices:  {stdop.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4c92bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick peek at each dataset\n",
    "print(\"=\" * 60)\n",
    "print(\"VOLATILITY SURFACE (vsurfd)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Columns: {list(vs.columns)}\")\n",
    "display(vs.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ZERO CURVE (zerocd)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Columns: {list(zc.columns)}\")\n",
    "display(zc.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STD OPTION PRICES (stdopd)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Columns: {list(stdop.columns)}\")\n",
    "display(stdop.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c1c42",
   "metadata": {},
   "source": [
    "## 2. Date Coverage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bf481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique dates from each dataset\n",
    "vs_dates = set(vs[\"date\"].dt.date)\n",
    "px_dates = set(px[\"date\"].dt.date)\n",
    "zc_dates = set(zc[\"date\"].dt.date)\n",
    "stdop_dates = set(stdop[\"date\"].dt.date)\n",
    "\n",
    "print(\"Date Coverage Summary:\")\n",
    "print(f\"  Vol Surface:  {len(vs_dates):,} unique dates | {min(vs_dates)} to {max(vs_dates)}\")\n",
    "print(f\"  Underlying:   {len(px_dates):,} unique dates | {min(px_dates)} to {max(px_dates)}\")\n",
    "print(f\"  Zero Curve:   {len(zc_dates):,} unique dates | {min(zc_dates)} to {max(zc_dates)}\")\n",
    "print(f\"  Std Option:   {len(stdop_dates):,} unique dates | {min(stdop_dates)} to {max(stdop_dates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02db923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find intersection of all dates\n",
    "common_dates = vs_dates & px_dates & zc_dates & stdop_dates\n",
    "print(f\"\\nCommon dates across ALL datasets: {len(common_dates):,}\")\n",
    "print(f\"  Range: {min(common_dates)} to {max(common_dates)}\")\n",
    "\n",
    "# Check what's missing from each\n",
    "print(\"\\nDates present in Vol Surface but missing from:\")\n",
    "print(f\"  Underlying:  {len(vs_dates - px_dates):,}\")\n",
    "print(f\"  Zero Curve:  {len(vs_dates - zc_dates):,}\")\n",
    "print(f\"  Std Option:  {len(vs_dates - stdop_dates):,}\")\n",
    "\n",
    "# The key constraint: we need vs_dates to be a subset of the others for Heston\n",
    "vs_minus_common = vs_dates - common_dates\n",
    "print(f\"\\n‚ö†Ô∏è  Vol surface dates NOT in common set: {len(vs_minus_common):,}\")\n",
    "if vs_minus_common:\n",
    "    print(f\"  Sample: {sorted(vs_minus_common)[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2197fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize date coverage\n",
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "\n",
    "datasets = {\n",
    "    \"Vol Surface\": vs_dates,\n",
    "    \"Underlying\": px_dates,\n",
    "    \"Zero Curve\": zc_dates,\n",
    "    \"Std Option\": stdop_dates,\n",
    "}\n",
    "\n",
    "for i, (name, dates) in enumerate(datasets.items()):\n",
    "    dates_sorted = sorted(dates)\n",
    "    ax.scatter(dates_sorted, [i] * len(dates_sorted), s=1, alpha=0.5, label=name)\n",
    "\n",
    "ax.set_yticks(range(len(datasets)))\n",
    "ax.set_yticklabels(list(datasets.keys()))\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_title(\"Date Coverage by Dataset\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1512677b",
   "metadata": {},
   "source": [
    "## 3. Maturity (Days) Grid Analysis\n",
    "\n",
    "Critical question: Do the maturities in `vsurfd` match those in `zerocd` and `stdopd`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c2ba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique days in each dataset\n",
    "vs_days = sorted(vs[\"days\"].unique())\n",
    "zc_days = sorted(zc[\"days\"].unique())\n",
    "stdop_days = sorted(stdop[\"days\"].unique())\n",
    "\n",
    "print(\"Maturity (days) Grid Summary:\")\n",
    "print(f\"\\nVol Surface ({len(vs_days)} unique):\")\n",
    "print(f\"  {vs_days}\")\n",
    "\n",
    "print(f\"\\nZero Curve ({len(zc_days)} unique):\")\n",
    "print(f\"  {zc_days[:20]}{'...' if len(zc_days) > 20 else ''}\")\n",
    "\n",
    "print(f\"\\nStd Option ({len(stdop_days)} unique):\")\n",
    "print(f\"  {stdop_days}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8bdd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check overlap\n",
    "vs_days_set = set(vs_days)\n",
    "zc_days_set = set(zc_days)\n",
    "stdop_days_set = set(stdop_days)\n",
    "\n",
    "print(\"Maturity Grid Alignment:\")\n",
    "print(f\"\\nVol Surface days in Zero Curve:  {len(vs_days_set & zc_days_set)}/{len(vs_days_set)}\")\n",
    "print(f\"Vol Surface days in Std Option:  {len(vs_days_set & stdop_days_set)}/{len(vs_days_set)}\")\n",
    "\n",
    "vs_not_in_zc = vs_days_set - zc_days_set\n",
    "vs_not_in_stdop = vs_days_set - stdop_days_set\n",
    "\n",
    "if vs_not_in_zc:\n",
    "    print(f\"\\n‚ö†Ô∏è  Vol Surface days NOT in Zero Curve: {sorted(vs_not_in_zc)}\")\n",
    "    print(\"   ‚Üí Will need to INTERPOLATE zero rates for these maturities\")\n",
    "else:\n",
    "    print(\"\\n‚úì All Vol Surface maturities found in Zero Curve\")\n",
    "\n",
    "if vs_not_in_stdop:\n",
    "    print(f\"\\n‚ö†Ô∏è  Vol Surface days NOT in Std Option: {sorted(vs_not_in_stdop)}\")\n",
    "    print(\"   ‚Üí Will need to INTERPOLATE forward prices for these maturities\")\n",
    "else:\n",
    "    print(\"\\n‚úì All Vol Surface maturities found in Std Option\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c755bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize maturity grids\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "y_pos = {\"Vol Surface\": 0, \"Zero Curve\": 1, \"Std Option\": 2}\n",
    "\n",
    "ax.scatter(vs_days, [0] * len(vs_days), s=50, marker='o', label=\"Vol Surface\", alpha=0.7)\n",
    "ax.scatter(zc_days, [1] * len(zc_days), s=20, marker='s', label=\"Zero Curve\", alpha=0.5)\n",
    "ax.scatter(stdop_days, [2] * len(stdop_days), s=50, marker='^', label=\"Std Option\", alpha=0.7)\n",
    "\n",
    "ax.set_yticks([0, 1, 2])\n",
    "ax.set_yticklabels([\"Vol Surface\", \"Zero Curve\", \"Std Option\"])\n",
    "ax.set_xlabel(\"Days to Maturity\")\n",
    "ax.set_title(\"Maturity Grid Comparison\")\n",
    "ax.set_xlim(-10, max(max(vs_days), max(zc_days), max(stdop_days)) + 20)\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "ax.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457ff274",
   "metadata": {},
   "source": [
    "## 4. Delta Grid Analysis (Vol Surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22b097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique deltas and cp_flag combinations\n",
    "vs_deltas = sorted(vs[\"delta\"].unique())\n",
    "vs_cp = sorted(vs[\"cp_flag\"].unique())\n",
    "\n",
    "print(\"Vol Surface Delta Grid:\")\n",
    "print(f\"  Deltas ({len(vs_deltas)}): {vs_deltas}\")\n",
    "print(f\"  CP flags: {vs_cp}\")\n",
    "\n",
    "# Expected grid size per date\n",
    "expected_grid_size = len(vs_days) * len(vs_deltas) * len(vs_cp)\n",
    "print(f\"\\nExpected full grid per date: {len(vs_days)} days √ó {len(vs_deltas)} deltas √ó {len(vs_cp)} cp = {expected_grid_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f3ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check grid completeness per date\n",
    "grid_size_per_date = vs.groupby(\"date\").size()\n",
    "\n",
    "print(\"Grid size per date:\")\n",
    "print(grid_size_per_date.describe())\n",
    "\n",
    "full_grid_dates = (grid_size_per_date == expected_grid_size).sum()\n",
    "print(f\"\\nDates with full grid: {full_grid_dates}/{len(grid_size_per_date)} ({100*full_grid_dates/len(grid_size_per_date):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0f0fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize grid completeness over time\n",
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "\n",
    "completeness = (grid_size_per_date / expected_grid_size * 100).reset_index()\n",
    "completeness.columns = [\"date\", \"pct_complete\"]\n",
    "\n",
    "ax.plot(completeness[\"date\"], completeness[\"pct_complete\"], linewidth=0.5, alpha=0.7)\n",
    "ax.axhline(100, color='g', linestyle='--', alpha=0.5, label='Full grid')\n",
    "ax.axhline(completeness[\"pct_complete\"].median(), color='r', linestyle=':', alpha=0.5, \n",
    "           label=f'Median ({completeness[\"pct_complete\"].median():.1f}%)')\n",
    "\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Grid Completeness (%)\")\n",
    "ax.set_title(\"Vol Surface Grid Completeness Over Time\")\n",
    "ax.set_ylim(0, 105)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c5dd9e",
   "metadata": {},
   "source": [
    "## 5. Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee86f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing/sentinel values in critical columns\n",
    "print(\"Missing Values Summary:\")\n",
    "print(\"\\nVol Surface:\")\n",
    "print(f\"  impl_volatility NaN:       {vs['impl_volatility'].isna().sum():,}\")\n",
    "print(f\"  impl_volatility == -99.99: {(vs['impl_volatility'] == -99.99).sum():,}\")\n",
    "print(f\"  dispersion == -99.99:      {(vs['dispersion'] == -99.99).sum():,}\")\n",
    "\n",
    "print(\"\\nZero Curve:\")\n",
    "print(f\"  rate NaN:  {zc['rate'].isna().sum():,}\")\n",
    "print(f\"  rate <= 0: {(zc['rate'] <= 0).sum():,}\")\n",
    "\n",
    "print(\"\\nStd Option:\")\n",
    "print(f\"  forward_price NaN:  {stdop['forward_price'].isna().sum():,}\")\n",
    "print(f\"  forward_price <= 0: {(stdop['forward_price'] <= 0).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6640e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of IV missingness by (days, delta) for a sample date\n",
    "sample_date = vs[\"date\"].iloc[len(vs)//2]\n",
    "sample = vs[vs[\"date\"] == sample_date].copy()\n",
    "\n",
    "# Create pivot for calls\n",
    "calls = sample[sample[\"cp_flag\"] == \"C\"].pivot_table(\n",
    "    index=\"days\", columns=\"delta\", values=\"impl_volatility\", aggfunc=\"first\"\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "mask = calls.isna() | (calls == -99.99)\n",
    "sns.heatmap(calls.where(~mask), annot=False, cmap=\"YlOrRd\", ax=ax,\n",
    "            cbar_kws={\"label\": \"Implied Volatility\"})\n",
    "ax.set_title(f\"Call IV Surface on {str(sample_date)[:10]} (white = missing)\")\n",
    "ax.set_xlabel(\"Delta\")\n",
    "ax.set_ylabel(\"Days to Maturity\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44658ec4",
   "metadata": {},
   "source": [
    "## 6. Forward Price / Carry Rate Analysis\n",
    "\n",
    "For Heston calibration, we need the carry rate $q(T)$ derived from:\n",
    "$$q(T) = r(T) - \\frac{1}{T} \\ln\\left(\\frac{F(T)}{S_0}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3549390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we can compute q(T) for common dates\n",
    "# Need: spot price, forward price, risk-free rate, all for the same (date, days)\n",
    "\n",
    "# Get spot prices\n",
    "px_spot = px[[\"date\", \"close\"]].copy()\n",
    "px_spot.columns = [\"date\", \"spot\"]\n",
    "\n",
    "# Get forward prices (one per date/days - should be same for C and P)\n",
    "fwd = stdop.groupby([\"date\", \"days\"])[\"forward_price\"].first().reset_index()\n",
    "\n",
    "# Get rates\n",
    "rates = zc[[\"date\", \"days\", \"rate\"]].copy()\n",
    "\n",
    "print(f\"Spot prices: {len(px_spot):,} dates\")\n",
    "print(f\"Forward prices: {len(fwd):,} (date, days) pairs\")\n",
    "print(f\"Rates: {len(rates):,} (date, days) pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e8638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to check coverage\n",
    "merged = fwd.merge(rates, on=[\"date\", \"days\"], how=\"inner\")\n",
    "merged = merged.merge(px_spot, on=\"date\", how=\"inner\")\n",
    "\n",
    "print(f\"Merged (date, days) with spot, forward, rate: {len(merged):,} rows\")\n",
    "print(f\"Unique dates: {merged['date'].nunique():,}\")\n",
    "print(f\"Unique days: {sorted(merged['days'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f97db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute implied carry rate q(T)\n",
    "merged[\"T\"] = merged[\"days\"] / 365.0\n",
    "merged[\"q\"] = merged[\"rate\"] - (1 / merged[\"T\"]) * np.log(merged[\"forward_price\"] / merged[\"spot\"])\n",
    "\n",
    "print(\"Implied Carry Rate q(T) Summary:\")\n",
    "print(merged[\"q\"].describe())\n",
    "\n",
    "# Check for anomalies\n",
    "anomalies = merged[(merged[\"q\"] < -0.1) | (merged[\"q\"] > 0.2)]\n",
    "print(f\"\\nAnomalous q values (< -10% or > 20%): {len(anomalies):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f4a3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot q(T) term structure for sample dates\n",
    "sample_dates = merged[\"date\"].drop_duplicates().iloc[::500].head(5).tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "for d in sample_dates:\n",
    "    curve = merged[merged[\"date\"] == d].sort_values(\"days\")\n",
    "    ax.plot(curve[\"days\"], curve[\"q\"] * 100, 'o-', label=str(d)[:10], markersize=6)\n",
    "\n",
    "ax.set_xlabel(\"Days to Maturity\")\n",
    "ax.set_ylabel(\"Carry Rate q(T) (%)\")\n",
    "ax.set_title(\"Implied Carry Rate Term Structure\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700c6bb2",
   "metadata": {},
   "source": [
    "## 7. Summary & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4998866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"DATA VALIDATION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìÖ DATE COVERAGE:\")\n",
    "print(f\"   Vol Surface dates:        {len(vs_dates):,}\")\n",
    "print(f\"   Common dates (all data):  {len(common_dates):,}\")\n",
    "pct_common = 100 * len(common_dates) / len(vs_dates)\n",
    "status = \"‚úì\" if pct_common > 95 else \"‚ö†Ô∏è\"\n",
    "print(f\"   {status} Coverage: {pct_common:.1f}%\")\n",
    "\n",
    "print(f\"\\nüìä MATURITY GRID:\")\n",
    "print(f\"   Vol Surface maturities: {vs_days}\")\n",
    "print(f\"   Std Option maturities:  {stdop_days}\")\n",
    "if vs_not_in_stdop:\n",
    "    print(f\"   ‚ö†Ô∏è  Need interpolation for: {sorted(vs_not_in_stdop)}\")\n",
    "else:\n",
    "    print(f\"   ‚úì All maturities aligned\")\n",
    "\n",
    "print(f\"\\nüî¢ GRID COMPLETENESS:\")\n",
    "print(f\"   Expected grid size: {expected_grid_size}\")\n",
    "print(f\"   Median actual:      {grid_size_per_date.median():.0f}\")\n",
    "print(f\"   Full grid dates:    {full_grid_dates}/{len(grid_size_per_date)}\")\n",
    "\n",
    "print(f\"\\nüí∞ HESTON INPUTS:\")\n",
    "print(f\"   Forward prices available: {len(merged):,} (date, T) pairs\")\n",
    "print(f\"   Carry rate q range: [{merged['q'].min():.4f}, {merged['q'].max():.4f}]\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RECOMMENDATIONS:\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44d9711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate specific recommendations\n",
    "recommendations = []\n",
    "\n",
    "if pct_common < 100:\n",
    "    missing_pct = 100 - pct_common\n",
    "    recommendations.append(\n",
    "        f\"DATES: {missing_pct:.1f}% of vol surface dates lack complete Heston inputs. \"\n",
    "        f\"Option 1: Filter to common dates only. Option 2: Forward-fill missing rates/forwards.\"\n",
    "    )\n",
    "\n",
    "if vs_not_in_stdop:\n",
    "    recommendations.append(\n",
    "        f\"MATURITIES: Maturities {sorted(vs_not_in_stdop)} are in vol surface but not in stdopd. \"\n",
    "        f\"Must interpolate forward prices for these tenors.\"\n",
    "    )\n",
    "\n",
    "if vs_not_in_zc:\n",
    "    recommendations.append(\n",
    "        f\"ZERO CURVE: Maturities {sorted(vs_not_in_zc)} need rate interpolation.\"\n",
    "    )\n",
    "\n",
    "if grid_size_per_date.median() < expected_grid_size * 0.9:\n",
    "    recommendations.append(\n",
    "        f\"GRID SPARSITY: Median grid fill is {100*grid_size_per_date.median()/expected_grid_size:.0f}%. \"\n",
    "        f\"VAE must handle missing values (masking) during training.\"\n",
    "    )\n",
    "\n",
    "if anomalies is not None and len(anomalies) > 0:\n",
    "    recommendations.append(\n",
    "        f\"CARRY RATES: {len(anomalies)} anomalous q(T) values detected. \"\n",
    "        f\"Consider filtering or capping extreme values.\"\n",
    "    )\n",
    "\n",
    "if not recommendations:\n",
    "    recommendations.append(\"‚úì Data looks well-aligned! Ready for processing.\")\n",
    "\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"\\n{i}. {rec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25c8bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save common dates list for downstream use\n",
    "common_dates_df = pd.DataFrame({\"date\": sorted(common_dates)})\n",
    "common_dates_path = RAW_DIR.parent / \"processed\" / \"common_dates.csv\"\n",
    "common_dates_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "common_dates_df.to_csv(common_dates_path, index=False)\n",
    "print(f\"Saved {len(common_dates_df)} common dates to: {common_dates_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
