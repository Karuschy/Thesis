{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2471aa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directories:\n",
      "  Vol surface:    C:\\Users\\Admin\\OneDrive\\Desktop\\Fifth Year\\Computer Science\\CS4490 Thesis\\Codebase\\Thesis\\data\\raw\\ivydb\\vol_surface\n",
      "  Security price: C:\\Users\\Admin\\OneDrive\\Desktop\\Fifth Year\\Computer Science\\CS4490 Thesis\\Codebase\\Thesis\\data\\raw\\ivydb\\security_price\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wrds\n",
    "\n",
    "# -------------------\n",
    "# USER CONFIG\n",
    "# -------------------\n",
    "WRDS_USERNAME = \"acaraman\"\n",
    "LIB = \"optionm\"\n",
    "\n",
    "TICKER = \"AAPL\"\n",
    "START_DATE = \"2016-01-01\"\n",
    "END_DATE   = \"2025-12-31\"\n",
    "\n",
    "YEARS = list(range(int(START_DATE[:4]), int(END_DATE[:4]) + 1))\n",
    "\n",
    "# -------------------\n",
    "# OUTPUT PATHS\n",
    "# -------------------\n",
    "RAW_IVYDB_DIR = Path(\"../../data/raw/ivydb\")\n",
    "\n",
    "# Subdirectories for each data type\n",
    "VOL_SURFACE_DIR = RAW_IVYDB_DIR / \"vol_surface\"\n",
    "SECURITY_PRICE_DIR = RAW_IVYDB_DIR / \"security_price\"\n",
    "\n",
    "# Create directories\n",
    "VOL_SURFACE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SECURITY_PRICE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Output directories:\")\n",
    "print(f\"  Vol surface:    {VOL_SURFACE_DIR.resolve()}\")\n",
    "print(f\"  Security price: {SECURITY_PRICE_DIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebae639b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n",
      "Connected to WRDS. Connection type: <class 'wrds.sql.Connection'>\n",
      "Engine type: <class 'sqlalchemy.engine.base.Engine'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_27908\\542716453.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  test_result = pd.read_sql(text(\"SELECT 1 AS test\"), conn)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Query must be a string unless using sqlalchemy.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Test the connection using engine.connect() with text()\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mconnect() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m---> 18\u001b[0m     test_result \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSELECT 1 AS test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (should be 1)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\OneDrive\\Desktop\\Fifth Year\\Computer Science\\CS4490 Thesis\\Codebase\\Thesis\\.venv\\lib\\site-packages\\pandas\\io\\sql.py:708\u001b[0m, in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[1;32m--> 708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m            \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m         _is_table_name \u001b[38;5;241m=\u001b[39m pandas_sql\u001b[38;5;241m.\u001b[39mhas_table(sql)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\OneDrive\\Desktop\\Fifth Year\\Computer Science\\CS4490 Thesis\\Codebase\\Thesis\\.venv\\lib\\site-packages\\pandas\\io\\sql.py:2728\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m   2717\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_query\u001b[39m(\n\u001b[0;32m   2718\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2719\u001b[0m     sql,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2726\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2727\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[1;32m-> 2728\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2729\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[0;32m   2731\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\OneDrive\\Desktop\\Fifth Year\\Computer Science\\CS4490 Thesis\\Codebase\\Thesis\\.venv\\lib\\site-packages\\pandas\\io\\sql.py:2660\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2658\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, sql: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m Select \u001b[38;5;241m|\u001b[39m TextClause, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sql, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m-> 2660\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery must be a string unless using sqlalchemy.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2661\u001b[0m     args \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [params]\n\u001b[0;32m   2662\u001b[0m     cur \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon\u001b[38;5;241m.\u001b[39mcursor()\n",
      "\u001b[1;31mTypeError\u001b[0m: Query must be a string unless using sqlalchemy."
     ]
    }
   ],
   "source": [
    "# Connect to WRDS - may prompt for password\n",
    "from sqlalchemy import text\n",
    "\n",
    "try:\n",
    "    db.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "db = wrds.Connection(wrds_username=WRDS_USERNAME)\n",
    "print(f\"Connected to WRDS. Connection type: {type(db)}\")\n",
    "\n",
    "# Get the underlying SQLAlchemy engine for direct queries\n",
    "engine = db.engine\n",
    "print(f\"Engine type: {type(engine)}\")\n",
    "\n",
    "# Test the connection using native SQLAlchemy execution\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT 1 AS test\"))\n",
    "    test_result = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "print(f\"Connection test: {test_result['test'].iloc[0]} (should be 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08add460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_tables(lib=LIB):\n",
    "    return set(db.list_tables(library=lib))\n",
    "\n",
    "def describe_cols(table, lib=LIB):\n",
    "    desc = db.describe_table(library=lib, table=table)\n",
    "    return desc[\"name\"].tolist(), desc\n",
    "\n",
    "def pick_col(cols, candidates, required=True):\n",
    "    cols_l = [c.lower() for c in cols]\n",
    "    for cand in candidates:\n",
    "        cand_l = cand.lower()\n",
    "        if cand_l in cols_l:\n",
    "            return cols[cols_l.index(cand_l)]\n",
    "    if required:\n",
    "        raise KeyError(f\"Could not find any of {candidates} in columns: {cols}\")\n",
    "    return None\n",
    "\n",
    "def has_table(table, lib=LIB):\n",
    "    return table in list_tables(lib)\n",
    "\n",
    "def run_query(sql, date_cols=None):\n",
    "    \"\"\"Run SQL query using native SQLAlchemy execution.\"\"\"\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(sql))\n",
    "        df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    if date_cols:\n",
    "        for col in date_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_datetime(df[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b52bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_secids_for_ticker(ticker: str, start_date: str, end_date: str, lib=LIB) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with a column 'secid' containing candidate secids for the ticker.\n",
    "    Tries:\n",
    "      1) optionm.secnmd with a direct ticker column (ticker/tic/symbol)\n",
    "      2) optionm.secnmd joined to optionm.ticker (tickerid -> ticker text)\n",
    "    \"\"\"\n",
    "    ticker = ticker.upper()\n",
    "\n",
    "    if not has_table(\"secnmd\", lib):\n",
    "        raise RuntimeError(f\"{lib}.secnmd not found. Available tables may differ.\")\n",
    "\n",
    "    secnmd_cols, _ = describe_cols(\"secnmd\", lib)\n",
    "\n",
    "    secid_col = pick_col(secnmd_cols, [\"secid\"], required=True)\n",
    "    # try common ticker string columns\n",
    "    tkr_col = pick_col(secnmd_cols, [\"ticker\", \"tic\", \"symbol\"], required=False)\n",
    "\n",
    "    # optional effective-date style columns\n",
    "    eff_col = pick_col(secnmd_cols, [\"date\", \"dt\", \"effectivedate\", \"effective_date\", \"effdate\", \"eff_date\"], required=False)\n",
    "    end_col = pick_col(secnmd_cols, [\"enddate\", \"end_date\", \"thrudate\", \"thru_date\"], required=False)\n",
    "\n",
    "    # Build an overlap filter if effective date ranges exist\n",
    "    # We want records that overlap [start_date, end_date]\n",
    "    overlap_filter = \"\"\n",
    "    if eff_col and end_col:\n",
    "        overlap_filter = f\"\"\"\n",
    "          AND {eff_col} <= '{end_date}'\n",
    "          AND ({end_col} IS NULL OR {end_col} >= '{start_date}')\n",
    "        \"\"\"\n",
    "    elif eff_col:\n",
    "        overlap_filter = f\" AND {eff_col} <= '{end_date}'\"\n",
    "\n",
    "    # Case 1: direct ticker string column exists\n",
    "    if tkr_col:\n",
    "        q = f\"\"\"\n",
    "        SELECT DISTINCT {secid_col} AS secid\n",
    "        FROM {lib}.secnmd\n",
    "        WHERE {tkr_col} = '{ticker}'\n",
    "        {overlap_filter}\n",
    "        \"\"\"\n",
    "        out = run_query(q)\n",
    "        if not out.empty:\n",
    "            return out\n",
    "\n",
    "    # Case 2: join through ticker table if secnmd has tickerid\n",
    "    tickerid_col = pick_col(secnmd_cols, [\"tickerid\", \"ticker_id\"], required=False)\n",
    "    if tickerid_col and has_table(\"ticker\", lib):\n",
    "        t_cols, _ = describe_cols(\"ticker\", lib)\n",
    "        t_id = pick_col(t_cols, [\"tickerid\", \"ticker_id\"], required=True)\n",
    "        t_txt = pick_col(t_cols, [\"ticker\", \"tic\", \"symbol\"], required=True)\n",
    "\n",
    "        q = f\"\"\"\n",
    "        SELECT DISTINCT sn.{secid_col} AS secid\n",
    "        FROM {lib}.secnmd sn\n",
    "        JOIN {lib}.ticker t\n",
    "          ON sn.{tickerid_col} = t.{t_id}\n",
    "        WHERE t.{t_txt} = '{ticker}'\n",
    "        {overlap_filter}\n",
    "        \"\"\"\n",
    "        out = run_query(q)\n",
    "        if not out.empty:\n",
    "            return out\n",
    "\n",
    "    raise RuntimeError(\n",
    "        \"Could not resolve secid for ticker. \"\n",
    "        \"Inspect optionm.secnmd and optionm.ticker schema to adjust mapping.\"\n",
    "    )\n",
    "\n",
    "secids = resolve_secids_for_ticker(TICKER, START_DATE, END_DATE)\n",
    "secids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b6349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_secid_by_surface_coverage(secids_df: pd.DataFrame, years=YEARS, lib=LIB) -> int:\n",
    "    \"\"\"\n",
    "    If multiple secids exist for a ticker, choose the one with the most distinct surface dates\n",
    "    across vsurfdYYYY tables within [START_DATE, END_DATE].\n",
    "    \"\"\"\n",
    "    if secids_df.empty:\n",
    "        raise RuntimeError(\"No secids provided.\")\n",
    "\n",
    "    secid_list = \",\".join(str(int(x)) for x in secids_df[\"secid\"].unique())\n",
    "\n",
    "    counts = []\n",
    "    for y in years:\n",
    "        t = f\"vsurfd{y}\"\n",
    "        if not has_table(t, lib):\n",
    "            continue\n",
    "        q = f\"\"\"\n",
    "        SELECT secid, COUNT(DISTINCT date) AS n_days\n",
    "        FROM {lib}.{t}\n",
    "        WHERE secid IN ({secid_list})\n",
    "          AND date BETWEEN '{START_DATE}' AND '{END_DATE}'\n",
    "        GROUP BY secid\n",
    "        \"\"\"\n",
    "        counts.append(run_query(q))\n",
    "\n",
    "    if not counts:\n",
    "        raise RuntimeError(\"No vsurfdYYYY tables found in the selected years.\")\n",
    "\n",
    "    cov = (pd.concat(counts, ignore_index=True)\n",
    "             .groupby(\"secid\", as_index=False)[\"n_days\"].sum()\n",
    "             .sort_values(\"n_days\", ascending=False))\n",
    "\n",
    "    display(cov.head(10))\n",
    "    return int(cov.iloc[0][\"secid\"])\n",
    "\n",
    "SECID = choose_best_secid_by_surface_coverage(secids)\n",
    "print(\"Chosen SECID:\", SECID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf54048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_surface_for_secid(secid: int, years=YEARS, lib=LIB) -> pd.DataFrame:\n",
    "    frames = []\n",
    "    for y in years:\n",
    "        t = f\"vsurfd{y}\"\n",
    "        if not has_table(t, lib):\n",
    "            continue\n",
    "\n",
    "        q = f\"\"\"\n",
    "        SELECT\n",
    "            secid,\n",
    "            date,\n",
    "            days,\n",
    "            delta,\n",
    "            cp_flag,\n",
    "            impl_volatility,\n",
    "            impl_strike,\n",
    "            impl_premium,\n",
    "            dispersion\n",
    "        FROM {lib}.{t}\n",
    "        WHERE secid = {secid}\n",
    "          AND date BETWEEN '{START_DATE}' AND '{END_DATE}'\n",
    "        \"\"\"\n",
    "        frames.append(run_query(q, date_cols=[\"date\"]))\n",
    "\n",
    "    if not frames:\n",
    "        raise RuntimeError(\"No surface data pulled. Check SECID/date range.\")\n",
    "\n",
    "    vs = pd.concat(frames, ignore_index=True)\n",
    "    return vs\n",
    "\n",
    "vs = pull_surface_for_secid(SECID)\n",
    "print(\"Surface shape:\", vs.shape)\n",
    "vs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9040212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_underlying_prices(secid: int, years=YEARS, lib=LIB) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Tries multiple common IvyDB/WRDS representations:\n",
    "      1) optionm.security_price if it contains secid\n",
    "      2) optionm.secprd (often a union/view) if it contains secid\n",
    "      3) optionm.secprdYYYY tables (yearly)\n",
    "    Returns a DataFrame with at least ['secid','date', ...]\n",
    "    \"\"\"\n",
    "    # 1) security_price\n",
    "    if has_table(\"security_price\", lib):\n",
    "        cols, _ = describe_cols(\"security_price\", lib)\n",
    "        id_col = pick_col(cols, [\"secid\", \"securityid\"], required=False)\n",
    "        date_col = pick_col(cols, [\"date\", \"dt\"], required=False)\n",
    "\n",
    "        if id_col and date_col:\n",
    "            # If it's keyed by secid, we're done\n",
    "            if id_col.lower() == \"secid\":\n",
    "                q = f\"\"\"\n",
    "                SELECT *\n",
    "                FROM {lib}.security_price\n",
    "                WHERE {id_col} = {secid}\n",
    "                  AND {date_col} BETWEEN '{START_DATE}' AND '{END_DATE}'\n",
    "                \"\"\"\n",
    "                return run_query(q, date_cols=[\"date\"])\n",
    "\n",
    "            # If it's keyed by securityid, we try to map secid -> securityid using optionm.security\n",
    "            if id_col.lower() == \"securityid\" and has_table(\"security\", lib):\n",
    "                s_cols, _ = describe_cols(\"security\", lib)\n",
    "                s_secid = pick_col(s_cols, [\"secid\"], required=False)\n",
    "                s_securityid = pick_col(s_cols, [\"securityid\"], required=False)\n",
    "\n",
    "                if s_secid and s_securityid:\n",
    "                    q_map = f\"\"\"\n",
    "                    SELECT DISTINCT {s_securityid} AS securityid\n",
    "                    FROM {lib}.security\n",
    "                    WHERE {s_secid} = {secid}\n",
    "                    \"\"\"\n",
    "                    m = run_query(q_map)\n",
    "                    if not m.empty:\n",
    "                        securityid = int(m.iloc[0][\"securityid\"])\n",
    "                        q = f\"\"\"\n",
    "                        SELECT *\n",
    "                        FROM {lib}.security_price\n",
    "                        WHERE {id_col} = {securityid}\n",
    "                          AND {date_col} BETWEEN '{START_DATE}' AND '{END_DATE}'\n",
    "                        \"\"\"\n",
    "                        out = run_query(q, date_cols=[\"date\"])\n",
    "                        out[\"secid\"] = secid\n",
    "                        return out\n",
    "\n",
    "    # 2) secprd (often a convenient union/view)\n",
    "    if has_table(\"secprd\", lib):\n",
    "        cols, _ = describe_cols(\"secprd\", lib)\n",
    "        id_col = pick_col(cols, [\"secid\"], required=False)\n",
    "        date_col = pick_col(cols, [\"date\", \"dt\"], required=False)\n",
    "        if id_col and date_col:\n",
    "            q = f\"\"\"\n",
    "            SELECT *\n",
    "            FROM {lib}.secprd\n",
    "            WHERE {id_col} = {secid}\n",
    "              AND {date_col} BETWEEN '{START_DATE}' AND '{END_DATE}'\n",
    "            \"\"\"\n",
    "            return run_query(q, date_cols=[\"date\"])\n",
    "\n",
    "    # 3) yearly secprdYYYY tables\n",
    "    frames = []\n",
    "    for y in years:\n",
    "        t = f\"secprd{y}\"\n",
    "        if not has_table(t, lib):\n",
    "            continue\n",
    "        cols, _ = describe_cols(t, lib)\n",
    "        id_col = pick_col(cols, [\"secid\"], required=False)\n",
    "        date_col = pick_col(cols, [\"date\", \"dt\"], required=False)\n",
    "        if not (id_col and date_col):\n",
    "            continue\n",
    "        q = f\"\"\"\n",
    "        SELECT *\n",
    "        FROM {lib}.{t}\n",
    "        WHERE {id_col} = {secid}\n",
    "          AND {date_col} BETWEEN '{START_DATE}' AND '{END_DATE}'\n",
    "        \"\"\"\n",
    "        frames.append(run_query(q, date_cols=[\"date\"]))\n",
    "\n",
    "    if frames:\n",
    "        return pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    raise RuntimeError(\"Could not pull underlying prices from security_price/secprd/secprdYYYY tables.\")\n",
    "\n",
    "px = pull_underlying_prices(SECID)\n",
    "print(\"Price shape:\", px.shape)\n",
    "px.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84539c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize delta: if it's 10..90, convert to 0.10..0.90\n",
    "if vs[\"delta\"].max() > 2:\n",
    "    vs[\"delta\"] = vs[\"delta\"] / 100.0\n",
    "\n",
    "# Cast days to int when safe\n",
    "vs[\"days\"] = vs[\"days\"].astype(int)\n",
    "\n",
    "# Ensure cp_flag uppercase\n",
    "vs[\"cp_flag\"] = vs[\"cp_flag\"].str.upper()\n",
    "\n",
    "vs[[\"date\",\"days\",\"delta\",\"cp_flag\",\"impl_volatility\",\"dispersion\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c78145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Surface date range:\", vs[\"date\"].min(), \"->\", vs[\"date\"].max())\n",
    "print(\"Unique dates:\", vs[\"date\"].nunique())\n",
    "print(\"Unique days:\", vs[\"days\"].nunique())\n",
    "print(\"Unique deltas:\", vs[\"delta\"].nunique())\n",
    "print(\"cp_flag:\", sorted(vs[\"cp_flag\"].unique()))\n",
    "\n",
    "print(\"\\nDispersion == -99.99 proportion:\", (vs[\"dispersion\"] == -99.99).mean())\n",
    "\n",
    "rows_per_day = vs.groupby(\"date\").size()\n",
    "print(\"\\nRows per date (describe):\")\n",
    "display(rows_per_day.describe())\n",
    "\n",
    "# Check grid stability (days x delta x cp)\n",
    "unique_days = vs[\"days\"].nunique()\n",
    "unique_deltas = vs[\"delta\"].nunique()\n",
    "expected_per_day = unique_days * unique_deltas * vs[\"cp_flag\"].nunique()\n",
    "print(\"\\nIf full grid were present each day, expected rows/day =\", expected_per_day)\n",
    "\n",
    "# A quick missingness view: how many (days,delta,cp) points per day?\n",
    "grid_points_per_day = vs.groupby([\"date\"]).apply(lambda g: g[[\"days\",\"delta\",\"cp_flag\"]].drop_duplicates().shape[0])\n",
    "print(\"\\nDistinct grid points per day (describe):\")\n",
    "display(grid_points_per_day.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef56f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to appropriate subdirectories\n",
    "vs_out = VOL_SURFACE_DIR / f\"{TICKER}_vsurfd_{START_DATE}_{END_DATE}.csv.gz\"\n",
    "px_out = SECURITY_PRICE_DIR / f\"{TICKER}_underlying_{START_DATE}_{END_DATE}.csv.gz\"\n",
    "\n",
    "vs.to_csv(vs_out, index=False, compression=\"gzip\")\n",
    "px.to_csv(px_out, index=False, compression=\"gzip\")\n",
    "\n",
    "print(\"Saved surface ->\", vs_out)\n",
    "print(\"Saved underlying ->\", px_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c160ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d46243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis (uv .venv)",
   "language": "python",
   "name": "thesis-uv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
